---
title: "FML3"
author: "Vijay"
date: '2022-03-04'
output: pdf_document
---


```{r}
library(dplyr)
library(caret)
library(ggplot2)
library(lattice)
library(rmarkdown)
library(e1071)
library(knitr)
```
```{r}
Original <- read.csv("UniversalBank.csv")
UniBank_df <- Original %>% select(Age, Experience, Income, Family, CCAvg, Education, Mortgage, Personal.Loan, Securities.Account, CD.Account, Online, CreditCard)
UniBank_df$CreditCard <- as.factor(UniBank_df$CreditCard)
UniBank_df$Personal.Loan <- as.factor((UniBank_df$Personal.Loan))
UniBank_df$Online <- as.factor(UniBank_df$Online)
```
```{r }
selected.var <- c(8,11,12)
set.seed(23)
train.index= createDataPartition(UniBank_df$Personal.Loan, p=0.60, list=FALSE)
traindata = UniBank_df[train.index,selected.var]
validationdata = UniBank_df[-train.index,selected.var]
```


```{r A}
attach(traindata)
ftable(CreditCard,Personal.Loan,Online)
detach(traindata)
```


probability is 53/(53+497) =53/550 = 0.096363
```{r B}
prop.table(ftable(traindata$CreditCard,traindata$Online,traindata$Personal.Loan),margin=1)
```


```{r C}
attach(traindata)
ftable(Personal.Loan,Online)
ftable(Personal.Loan,CreditCard)
detach(traindata)
```

```{r D}
prop.table(ftable(traindata$Personal.Loan,traindata$CreditCard),margin=1)
prop.table(ftable(traindata$Personal.Loan,traindata$Online),margin=1)
```

Di) 92/288 = 0.3194 or 31.94%

Dii) 167/288 = 0.5798 or 57.986%

Diii) total loans= 1 from table (288)  divided by total count from table (3000) = 0.096 or 9.6%

DiV) 812/2712 = 0.2994 or 29.94%

DV) 1624/2712 = 0.5988 or 59.88%

DVi) total loans=0 from table(2712) divided by total count from table (3000) = 0.904 or 90.4%

E)Naive Bayes calculation
    (0.3194 * 0.5798 * 0.096)/[(0.3194 * 0.5798 * 0.096)+(0.2994 * 0.5988 * 0.904)]
    = 0.0988505642823701 or 9.885%

F)B is more accurate.
``` 
```{r G}
Universalbank.nb <- naiveBayes(Personal.Loan ~ ., data = traindata)
Universalbank.nb
```
```{r NB confusion matrix for traindata}
pred.class <- predict(Universalbank.nb, newdata = traindata)
confusionMatrix(pred.class, traindata$Personal.Loan)
```

Despite being extremely sensitive, this model had a low specificity. All values were expected to be zero in the model, however the reference had all true values. Due to the large amount of 0 values, the model still gives a 90.4 percent accuracy despite missing all 1 data.
## Validation set

```{r}
#confusionMatrix
pred.prob <- predict(Universalbank.nb, newdata=validationdata, type="raw")
pred.class <- predict(Universalbank.nb, newdata = validationdata)
confusionMatrix(pred.class, validationdata$Personal.Loan)
```

```{r ROC}
library(pROC)

roc(validationdata$Personal.Loan,pred.prob[,1])
plot.roc(validationdata$Personal.Loan,pred.prob[,1],print.thres="best")
```
This suggests that lowering the sensitivity to 0.495 and boosting the specificity to 0.576 by setting a threshold of 0.906 could enhance the model.